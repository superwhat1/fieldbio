library(ggplot2)
qplot(x=speed,y=dist,data=cars)
FData = read.csv("./Data/FallopiaData.csv")
head(FData)
qplot(x=Total,data=FData)
qplot(x=10^Total,data=FData)
qplot(x=log(10^Total),data=FData)
qplot(x=Scenario,data=FData)
qplot(x=Silene,y=Total,data=FData)
qplot(x=Nutrients,y=Total,data=FData)
qplot(x=Total,data=FData,binwidth=9)
qplot(x=Total,data=FData, binwidth=0.5)
qplot(x=Total,data=FData,fill=Nutrients)
qplot(x=Total,data=FData,fill=Nutrients, posit="dodge")
qplot(x=Silene,y=Fallopia,data=FData,size=Total)
qplot(x=Silene,y=Fallopia,data=FData,colour = Total)
qplot(x=Silene,y=Fallopia,data=FData,colour=Total,size=I(50))
qplot(x=Silene,y=Fallopia,data=FData,colour=Total,size=50)
qplot(x=Silene,y=Fallopia,data=FData,colour=I("Purple"))
qplot(x=Silene,y=Fallopia,data=FData,colour=Total, alpha = 0.3)
qplot(x=Silene,y=Fallopia,data=FData,sizer=Total, alpha = 0.3)
qplot(x=Silene,y=Fallopia,data=FData,size=Total, alpha = 0.3)
qplot(x=Silene,y=Fallopia,data=FData,size=Total, alpha = I(0.3))
qplot(x=Silene,y=Fallopia,data=FData,size=I(5),fill=I("yellow"), colour=I("red"),shape= I(21))
qplot(x=Silene,y=Fallopia,data=FData,size=I(5),fill=I("yellow"), colour=I("red"),shape= I(43))
qplot(x=Silene,y=Fallopia,data=FData,size=I(5),fill=I("yellow"), colour=I("red"),shape= I(65))
qplot(x=Silene,y=Fallopia,data=FData,size=I(5),fill=I("yellow"), colour=I("red"),shape= I(11))
qplot(x=Silene,y=Fallopia,data=FData,size=I(5),fill=I("yellow"), colour=I("red"),shape= I(100))
qplot(x=Silene,y=Fallopia,data=FData,size=I(5),fill=I("yellow"), colour=I("red"),shape= I(69))
qplot(x=Silene,y=Fallopia,data=FData,size=I(5),fill=I("yellow"), colour=I("red"),shape= I(34))
qplot(x=Silene,y=Fallopia,data=FData,size=I(5),fill=I("yellow"), colour=I("red"),shape= I(500))
qplot(x=Silene,y=Fallopia,data=FData,size=I(5),fill=I("yellow"), colour=I("red"),shape= I(50))
qplot(x=Silene,y=Fallopia,data=FData,size=I(5),fill=I("yellow"), colour=I("red"),shape= I(21))
qplot(x=Silene,y=Fallopia,data=FData,xlab="Silene Biomass", y="Fallopia Biomass", main="Figure 1")
qplot(x=Silene,y=Fallopia,data=FData,xlab="Silene Biomass", ylab="Fallopia Biomass", main="Figure 1")
qplot(x=Silene,y=Fallopia,data=FData,size=Total, alpha = I(0.3))+teme_classic()
qplot(x=Silene,y=Fallopia,data=FData,size=Total, alpha = I(0.3))+theme_classic()
qplot(x=Silene,y=Fallopia,data=FData,size=Total,geom="boxplot")
qplot(x=Nutrients,y=Total,data=FData,size=Total,geom="boxplot")
qplot(x=Silene,data=FData, facets=Nutrients~.)
qplot(x=Silene,data=FData, facets=.~Nutrients)
qplot(x=Nutrients,y=Total,data=FData,size=Total,geom="boxplot")
qplot(x=Silene,data=FData, facets=.Scenario~Nutrients)
qplot(x=Silene,data=FData, facets=.Scenario~Nutrients)
qplot(x=Silene,data=FData, facets=Scenario~Nutrients)
Lythrum_2017 = read.csv("Lythrum/Lythrum2017FieldData.csv")
PL_complete = read.csv("Lythrum/PL_complete.csv")
PL_complete = read.csv("./PL_complete.csv")
PL_complete = read.csv("PL_complete.csv")
PL_complete = read.csv("./PL_complete.csv")
PL_complete = read.csv("./PL_complete.csv")
PL_complete = read.csv("./Lythrum/PL_complete.csv")
Lythrum_2017 = read.csv("./Lythrum/Lythrum2017FieldData.csv")
View(FData)
rm(FData)
View(PL_complete)
View(Lythrum_2017)
paste(PL_complete$Block,Lythrum_2017$BLOCK)
# Combine columns with the paste function
paste(PL_complete$Block,Lythrum_2017$BLOCK, sep='-') # sep is the separator string
merge?
merge()?
?merge()
# Rename Block column to "BLOCK" in PL_complete dataset so they have have the same column for merging
names(PL_complete)
PL_complete$BLOCK = PL_complete$Block
PL_complete$BLOCK = NULL
View(PL_complete)
PL_complete$BLOCK = PL_complete$Block
PL_complete$Block = NULL
# Rename Block column to "BLOCK" in PL_complete dataset so they have have the same column for merging
names(PL_complete)[4]
PL_complete = read.csv("./Lythrum/PL_complete.csv")
Lythrum_2017 = read.csv("./Lythrum/Lythrum2017FieldData.csv")
# Rename Block column to "BLOCK" in PL_complete dataset so they have have the same column for merging
names(PL_complete)[4] = "BLOCK"
View(PL_complete)
names(PL_complete)
# Add a merging column called BL_ID to each dataset
PL_complete$BL_ID = paste(PL_complete$BLOCK,PL_complete$ID,sep='-')
# Add a merging column called BL_ID to each dataset
PL_complete$BL_ID = paste(PL_complete$BLOCK, PL_complete$ID, sep='-')
Lythrum_2017$BL_ID = paste(Lythrum_2017$BLOCK, Lythrum_2017$ID, sep='-')
view(Lythrum_2017)
View(Lythrum_2017)
merge(PL_complete,Lythrum_2017,by=BL_ID)
merge(PL_complete, Lythrum_2017, by=BL_ID)
merge(PL_complete, Lythrum_2017, by='BL_ID')
PL_merged = merge(PL_complete, Lythrum_2017, by='BL_ID')
View(PL_merged)
str(PL_merged)
str(PL_complete)
#Check for duplicated rows
duplicated(PL_complete$BL_ID)
#Check for duplicated rows
duplicated(PL_complete$BL_ID) == TRUE
#Check for duplicated rows
PL_complete$BL_ID[duplicated(PL_complete$BL_ID),]
#Check for duplicated rows
PL_complete[duplicated(PL_complete$BL_ID),]
sum(duplicated(PL_complete$BL_ID))
sum(duplicated(Lythrum_2017$BL_ID)
sum(duplicated(Lythrum_2017$BL_ID))
c(PL_complete$BL_ID,Lythrum_2017$BL_ID)
BL_ID = c(PL_complete$BL_ID,Lythrum_2017$BL_ID)
!duplicated(BL_ID)
sum(!duplicated(BL_ID))
View(PL_complete)
View(Lythrum_2017)
# Sort BL_ID using the order() function
BL_ID = BL_ID[order(BL_ID)]
sum(!duplicated(BL_ID))
print(BL_ID)
print(BL_ID[1000:])
print(BL_ID[1000,])
print(BL_ID[1000:2000])
print(BL_ID[2000:3000])
print(BL_ID[3000:4000])
print(BL_ID[4000:5000])
print(BL_ID[5000:6000])
uniq= BL_ID [!duplicated(BL_ID)]
print(BL_ID[0:1000])
# Merge while keeping missing values
Merged_w_missing = merge(PL_complete, Lythrum_2017, by="BL_ID", all=TRUE)
View(Merged_w_missing)
# Check for missing data using BLOCK.y and BLOCK.x
Merged_w_missing[is.na(Merged_w_missing$BLOCK.x),]
Merged_w_missing[is.na(Merged_w_missing$BLOCK.y),]
write.csv(Merged_w_matching,'./Lythrum/Scrubbed_Lythrum_Data',col.names = FALSE)
write.csv(Merged_w_matching,'./Lythrum/Scrubbed_Lythrum_Data',col.names = NA)
write.csv(Merged_w_matching,'./Lythrum/Scrubbed_Lythrum_Data',row.names = NA)
write.csv(Merged_w_matching,'./Lythrum/Scrubbed_Lythrum_Data',row.names = FALSE)
# Merge and remove missing data
Merged_w_matching = merge(PL_complete,Lythrum_2017,by='BL_ID', all=FALSE)
write.csv(Merged_w_matching,'./Lythrum/Scrubbed_Lythrum_Data',row.names = FALSE)
View(Lythrum_2017)
View(Merged_w_matching)
View(Merged_w_matching)
View(Merged_w_missing)
str(Merged_w_missing)
str(Merged_w_matching)
View(Lythrum_2017)
#Check for duplicated rows
PL_complete[duplicated(PL_complete$BL_ID),]
sum(duplicated(PL_complete$BL_ID))
sum(duplicated(Lythrum_2017$BL_ID))
uniq= BL_ID [!duplicated(BL_ID)]
sum(!duplicated(BL_ID))
# Check for missing data using BLOCK.y and BLOCK.x
Merged_w_missing[is.na(Merged_w_missing$BLOCK.x),]
Merged_w_missing[is.na(Merged_w_missing$BLOCK.y),]
Merged_w_missing[is.na(Merged_w_missing$BLOCK.y),]
# Replace NA, dead, missing and others with 0
Merged_w_matching[is.na(Merged_w_matching)]=0
# Merge and remove missing data
Merged_w_matching = merge(PL_complete,Lythrum_2017,by='BL_ID', all=FALSE)
# Replace NA, dead, missing and others with 0
Merged_w_matching[is.na(Merged_w_matching)]=0
PL_complete = read.csv("./Lythrum/PL_complete.csv", stringsAsFactors = FALSE)
Lythrum_2017 = read.csv("./Lythrum/Lythrum2017FieldData.csv", stringsAsFactors = FALSE)
# Combine columns with the paste function
paste(PL_complete$Block,Lythrum_2017$BLOCK, sep='-') # sep is the separator string
# Rename Block column to "BLOCK" in PL_complete dataset so they have have the same column for merging
names(PL_complete)[4] = "BLOCK"
names(PL_complete)
# Add a merging column called BL_ID to each dataset
PL_complete$BL_ID = paste(PL_complete$BLOCK, PL_complete$ID, sep='-')
Lythrum_2017$BL_ID = paste(Lythrum_2017$BLOCK, Lythrum_2017$ID, sep='-')
PL_merged = merge(PL_complete, Lythrum_2017, by='BL_ID')
View(PL_merged)
# No duplicates in either dataset
# Check for unique values
BL_ID = c(PL_complete$BL_ID,Lythrum_2017$BL_ID)
# Sort BL_ID using the order() function
BL_ID = BL_ID[order(BL_ID)]
uniq= BL_ID [!duplicated(BL_ID)]
sum(!duplicated(BL_ID))
# Merge while keeping missing values
Merged_w_missing = merge(PL_complete, Lythrum_2017, by="BL_ID", all=TRUE)
# Check for missing data using BLOCK.y and BLOCK.x
Merged_w_missing[is.na(Merged_w_missing$BLOCK.x),]
Merged_w_missing[is.na(Merged_w_missing$BLOCK.y),]
# Merge and remove missing data
Merged_w_matching = merge(PL_complete,Lythrum_2017,by='BL_ID', all=FALSE)
# Replace NA, dead, missing and others with 0
Merged_w_matching[is.na(Merged_w_matching)]=0
# Write csv to file
write.csv(Merged_w_matching,'./Lythrum/Scrubbed_Lythrum_Data',row.names = FALSE)
gsub('Dead',0,Merged_w_matching)
gsub('missing',0,Merged_w_matching)
PL_complete = read.csv("./PL_refined.csv.csv", stringsAsFactors = FALSE)
PL_complete = read.csv("./Lythrum/PL_refined.csv.csv", stringsAsFactors = FALSE)
Lythrum_2017 = read.csv("./Lythrum/Lythrum2017FieldData.csv", stringsAsFactors = FALSE)
PL_complete = read.csv("./Lythrum/PL_refined.csv", stringsAsFactors = FALSE)
Lythrum_2017 = read.csv("./Lythrum/Lythrum2017FieldData.csv", stringsAsFactors = FALSE)
# Combine columns with the paste function
paste(PL_complete$Block,Lythrum_2017$BLOCK, sep='-') # sep is the separator string
# Rename Block column to "BLOCK" in PL_complete dataset so they have have the same column for merging
names(PL_complete)[4] = "BLOCK"
names(PL_complete)
# Add a merging column called BL_ID to each dataset
PL_complete$BL_ID = paste(PL_complete$BLOCK, PL_complete$ID, sep='-')
Lythrum_2017$BL_ID = paste(Lythrum_2017$BLOCK, Lythrum_2017$ID, sep='-')
PL_merged = merge(PL_complete, Lythrum_2017, by='BL_ID')
View(PL_merged)
str(PL_merged)
str(PL_complete)
#Check for duplicated rows
PL_complete[duplicated(PL_complete$BL_ID),]
sum(duplicated(PL_complete$BL_ID))
sum(duplicated(Lythrum_2017$BL_ID))
# No duplicates in either dataset
# Check for unique values
BL_ID = c(PL_complete$BL_ID,Lythrum_2017$BL_ID)
# Sort BL_ID using the order() function
BL_ID = BL_ID[order(BL_ID)]
uniq= BL_ID [!duplicated(BL_ID)]
sum(!duplicated(BL_ID))
# Merge while keeping missing values
Merged_w_missing = merge(PL_complete, Lythrum_2017, by="BL_ID", all=TRUE)
# Check for missing data using BLOCK.y and BLOCK.x
Merged_w_missing[is.na(Merged_w_missing$BLOCK.x),]
Merged_w_missing[is.na(Merged_w_missing$BLOCK.y),]
# Merge and remove missing data
Merged_w_matching = merge(PL_complete,Lythrum_2017,by='BL_ID', all=FALSE)
# Replace NA, dead, missing and others with 0
Merged_w_matching[is.na(Merged_w_matching)]=0
# Write csv to file
write.csv(Merged_w_matching,'./Lythrum/Scrubbed_Lythrum_Data',row.names = FALSE)
View(Merged_w_matching)
PL_complete = read.csv("./Lythrum/PL_refined.csv", stringsAsFactors = FALSE)
Lythrum_2017 = read.csv("./Lythrum/Lythrum2017FieldData.csv", stringsAsFactors = FALSE)
library(tidyverse)
library(vegan)
library(lmtest)
library(car)
library(coefplot)
#Open datasets
PL_complete = read.csv("./Lythrum/PL_refined.csv", stringsAsFactors = FALSE)
Lythrum_2017 = read.csv("./Lythrum/Lythrum2017FieldData.csv", stringsAsFactors = FALSE)
# Replace NA with zero, this only affects the stem height, stem count and damage columns
trimws(PL_complete)
#Open datasets
PL_complete = read.csv("./Lythrum/PL_refined.csv", stringsAsFactors = FALSE)
Lythrum_2017 = read.csv("./Lythrum/Lythrum2017FieldData.csv", stringsAsFactors = FALSE)
# Replace NA with zero, this only affects the stem height, stem count and damage columns
trimws(PL_complete)
trimws(Lythrum_2017)
PL_complete$File = NULL
sum(is.na(PL_complete[Damage]))
sum(is.na(PL_complete$Damage))
gsub('NA',NA,PL_complete)
sum(is.na(PL_complete$Damage))
sum(is.na(PL_complete))
gsub('NA',NA,Lythrum_2017)
sum(is.na(Lythrum_2017))
# Rename Block column to "BLOCK" in PL_complete dataset so they have have the same column for merging
names(PL_complete)[3] = "BLOCK"
names(PL_complete)
# Add a merging column called BL_ID to each dataset
PL_complete$BL_ID = paste(PL_complete$BLOCK, PL_complete$ID, sep='-')
Lythrum_2017$BL_ID = paste(Lythrum_2017$BLOCK, Lythrum_2017$ID, sep='-')
View(Lythrum_2017)
# Merge while keeping missing values
Merged_w_missing = merge(PL_complete, Lythrum_2017, by="BL_ID", all=TRUE)
# Check for missing data using BLOCK.y and BLOCK.x
Merged_w_missing[is.na(Merged_w_missing$BLOCK.x),]
Merged_w_missing[is.na(Merged_w_missing$BLOCK.y),]
# Merge and remove missing data
Merged_w_matching = merge(PL_complete,Lythrum_2017,by='BL_ID', all=FALSE)
library(ggplot2)
#New dataset with NA replaced with zero
PL_0 = PL_complete
#Open datasets
PL_complete = read.csv("./Lythrum/PL_refined.csv", stringsAsFactors = FALSE)
Lythrum_2017 = read.csv("./Lythrum/Lythrum2017FieldData.csv", stringsAsFactors = FALSE)
# Replace NA with zero, this only affects the stem height, stem count and damage columns
trimws(PL_complete)
# Replace NA with zero, this only affects the stem height, stem count and damage columns
PL_complete$File = NULL
trimws(Lythrum_2017)
gsub('NA',NA,PL_complete)
gsub('NA',NA,Lythrum_2017)
# Rename Block column to "BLOCK" in PL_complete dataset so they have have the same column for merging
names(PL_complete)[3] = "BLOCK"
#New dataset with NA replaced with zero
PL_0 = PL_complete
PL_0[is.na(PL_0)]=0
# Add a merging column called BL_ID to each dataset
PL_0$BL_ID = paste(PL_0$BLOCK, PL_0$ID, sep='-')
Lythrum_2017$BL_ID = paste(Lythrum_2017$BLOCK, Lythrum_2017$ID, sep='-')
PL_merged_w_match = merge(PL_0, Lythrum_2017, by='BL_ID', all = FALSE)
# Merge while keeping missing values
Merged_w_missing = merge(PL_0, Lythrum_2017, by="BL_ID", all=TRUE)
# Write csv to file
Muzz = subset(Merged_w_missing, SOURCE == 'M')
Eugene = subset(Merged_w_missing, SOURCE == 'E')
write.csv(PL_merged_w_match,'./Lythrum/PL_merged_w_match',row.names = FALSE)
setwd("~/Documents/Field Genomics/Final Project")
library(ggplot2)
library(ggplot2)
PL_complete = read.csv("./Lythrum/PL_refined.csv", stringsAsFactors = FALSE)
Lythrum_2017 = read.csv("./Lythrum/Lythrum2017FieldData.csv", stringsAsFactors = FALSE)
# Replace NA with zero, this only affects the stem height, stem count and damage columns
PL_complete$File = NULL
trimws(PL_complete)
trimws(Lythrum_2017)
gsub('NA',NA,PL_complete)
gsub('NA',NA,Lythrum_2017)
# Rename Block column to "BLOCK" in PL_complete dataset so they have have the same column for merging
names(PL_complete)[3] = "BLOCK"
# Add a merging column called BL_ID to each dataset
PL_complete$BL_ID = paste(PL_complete$BLOCK, PL_complete$ID, sep='-')
Lythrum_2017$BL_ID = paste(Lythrum_2017$BLOCK, Lythrum_2017$ID, sep='-')
#New dataset with NA replaced with zero
PL_0 = PL_complete
PL_0[is.na(PL_0)]=0
PL_match_0 = merge(PL_0, Lythrum_2017, by='BL_ID', all = FALSE)
PL_match_c = merge(PL_complete, Lythrum_2017, by='BL_ID', all = FALSE)
# Merge while keeping missing values
PL_miss_0 = merge(PL_0, Lythrum_2017, by="BL_ID", all=TRUE)
PL_miss_c = merge(PL_complete, Lythrum_2017, by="BL_ID", all=TRUE)
#Extract Muzz and Eugene experiments
Muzz = subset(PL_miss_c, SOURCE == 'M')
Eugene = subset(PL_miss_c, SOURCE == 'E')
# Write csv to file
write.csv(Muzz,'./Lythrum/Muzz_Data', row.names = FALSE)
write.csv(Eugene, './Lythrum/Eugene_Data', row.names = FALSE)
write.csv(PL_match_0,'./Lythrum/PL_match_0', row.names = FALSE)
write.csv(PL_match_0,'./Lythrum/PL_match_c', row.names = FALSE)
write.csv(PL_match_0,'./Lythrum/PL_miss_0', row.names = FALSE)
write.csv(PL_match_0,'./Lythrum/PL_miss_c', row.names = FALSE)
Muzz = read.csv('./Lythrum/Eugene_Data')
Eugene = read.csv('./Lythrum/Eugene_Data')
PL_match_0 = read.csv("./Lythrum/PL_match_0")
PL_match_c = read.csv("./Lythrum/PL_match_c")
PL_miss_0 = read.csv("./Lythrum/PL_miss_0")
PL_miss_c = read.csv("./Lythrum/PL_miss_c")
View(Eugene)
library(ggplot2)
library(car)
Muzz = read.csv('./Lythrum/Eugene_Data')
Eugene = read.csv('./Lythrum/Eugene_Data')
PL_match_0 = read.csv("./Lythrum/PL_match_0")
PL_match_c = read.csv("./Lythrum/PL_match_c")
PL_miss_0 = read.csv("./Lythrum/PL_miss_0")
PL_miss_c = read.csv("./Lythrum/PL_miss_c")
mod1 = lm(Damage~Stem.Length+Stem.Count+LAT+FAMFULL+HERB+VEGWT+RWT, data=Eugene)
car::qqp(Eugene$Damage, "norm")
plot(density(Eugene$Damage)) # does it fit a normal distribution?
#plot(density(Eugene$Damage)) # does it fit a normal distribution?
bptest(mod1) #check for homoskedastity
library(lmtest)
#plot(density(Eugene$Damage)) # does it fit a normal distribution?
bptest(mod1) #check for homoskedastity
plot(mod1)
mod2 = lm(Damage~LAT*Stem.Length, data=Eugene)
summary(mod2)
mod3 = lm(Damage~log(LAT), data=Eugene)
summary(mod3)
mod2 = lm(Damage~LAT*Stem.Length, data=Eugene)
summary(mod2)
mod3 = lm(Damage~log(LAT), data=Eugene)
summary(mod3)
mod3 = lm(Damage~I(log(LAT)), data=Eugene)
summary(mod3)
mod2 = lm(Damage~LAT*Stem.Length, data=Eugene)
summary(mod2)
mod3 = lm(Damage~I(log(LAT)), data=Eugene)
summary(mod3)
#plot(density(Eugene$Damage)) # does it fit a normal distribution?
bptest(mod1) #check for homoskedastity
plot(mod1)
mod3 = lm(log(Damage+1)~LAT, data=Eugene)
summary(mod3)
qplot(x=LAT, y=Damage, data=Eugene, geom="boxplot")
library(ggplot2)
library(car)
library(lmtest)
library(plyr)
library(dplyr)
Muzz = read.csv('./Lythrum/Eugene_Data')
Eugene = read.csv('./Lythrum/Eugene_Data')
PL_match_0 = read.csv("./Lythrum/PL_match_0")
PL_match_c = read.csv("./Lythrum/PL_match_c")
PL_miss_0 = read.csv("./Lythrum/PL_miss_0")
PL_miss_c = read.csv("./Lythrum/PL_miss_c")
mod1 = lm(Damage~LAT+VEGWT+Stem.Length+Stem.Count+RWT, data=Eugene)
car::qqp(Eugene$Damage, "norm")
#plot(density(Eugene$Damage)) # does it fit a normal distribution?
bptest(mod1) #check for homoskedastity
summary(mod1)
# Stem.length is significantly correlated to Damage
# Stem.Count is significantly correlated to Damage
# Previous years vegetative weight is significantly correlated to damage
# Previous years root weight is slightly significantly correlated to Damage
# No apparent correlation between LAT and Damage FOR NOW --- CORRELATION IS SHOWN LATER
plot(mod1)
diff = max(Eugene$LAT, na.rm = T)-min(Eugene$LAT, na.rm = T)
print(diff)
cutoff = diff/3.0
print(cutoff)
Min_LAT =min(Eugene$LAT, na.rm = T)
Min_LAT
South = Min_LAT+cutoff
South
# NA is evaluated as a value within the South range, so we remove those columns/ make them zeros
Eugene = Eugene[Eugene$FAMFULL!='P137',]
Eugene = Eugene[Eugene$FAMFULL!='P176',]
#Make new column Origin, group by LAT and replace with 1_North, 2_Mid and 3_South
Eugene$Origin = Eugene$LAT
Eugene$Origin[Eugene$Origin >= Min_LAT & Eugene$Origin<= Min_LAT+cutoff ] = '3_South'
Eugene$Origin[Eugene$Origin > Min_LAT+cutoff & Eugene$Origin <=Min_LAT+2*cutoff]= '2_Mid'
Eugene$Origin[Eugene$Origin > Min_LAT+2*cutoff]= '1_North'
FAM_mean = ddply(Eugene,~FAMFULL,summarise,LAT_mean=mean(LAT),Dam_mean=mean(Damage),VEGWT_mean=mean(VEGWT,na.rm = T),SL_mean=mean(Stem.Length), SC_mean = mean(Stem.Count))
POP_mean = ddply(Eugene,~POP,summarise,LAT_mean=mean(LAT),Dam_mean=mean(Damage),VEGWT_mean=mean(VEGWT,na.rm = T), SL_mean=mean(Stem.Length), SC_mean = mean(Stem.Count))
Origin_mean = ddply(Eugene,~Origin,summarise,LAT_mean=mean(LAT),Dam_mean=mean(Damage),VEGWT_mean=mean(VEGWT,na.rm = T), SL_mean=mean(Stem.Length), SC_mean = mean(Stem.Count))
mod2 = lm(Damage~LAT*Stem.Length, data=Eugene)
summary(mod2)
mod3 = lm(log(Damage+1)~LAT*Stem.Length, data=Eugene)
summary(mod3)
mod4 = lm(Damage~SOURCE,data=PL_match_0)
summary(mod4)
mod5 = lm(Dam_mean~VEGWT_mean, data=POP_mean)
summary(mod5)
#There is significant correlation between Damage and Stem Length when Grouped by Population
#There is slightly significant between Damage and Vegetative weight from previous year when Grouped by Population
mod6 = lm(Stem.Length~LAT, data=Eugene)
summary(mod6)
qplot(x=LAT_mean, y=Dam_mean, data=POP_mean, colour=POP) +theme_classic()
#Nice graph for Stem Length and Damage correlation
qplot(x=SL_mean, y=Dam_mean, data=POP_mean, colour=POP) +theme_classic()
#Plot for Vegetative weight against Damage
qplot(x=VEGWT_mean, y=Dam_mean, data=POP_mean, colour=POP) +theme_classic()
#Plot of Stem Length against LAT for Eugene
qplot(x=LAT, y=Stem.Length, data=Eugene, colour=POP) +theme_classic()
#Plot of Stem Length against LAT for POP_mean
qplot(x=LAT_mean, y=SL_mean, data=POP_mean, colour=POP) +theme_classic()
qplot(x=LAT_mean, y=Dam_mean, data=Origin_mean, colour = Origin, shape= Origin) +theme_classic()
# Small but significant Damage associated with the Mid Origin of the plants, I will look into the areas given by the Latitude groupings. I want to see if this latitude is similar to that of the natural/original habitat of the Lythrum, before it was introduced to north america.
library(lme4)
LMM1<-lmer(Stem.Length~BL_ID*Origin+(1|FAMFULL), data=Eugene)
library(lme4)
FloristicSurvey <- read.csv("/home/superwhat/Documents/Field Genomics/R Practice/Rob_summercourse/May9_floristicsurvey.csv")
MyData<-FloristicSurvey[,1:10]
MyData$Population<-as.factor(MyData$Population)
SpeciesComp<-FloristicSurvey[,11:length(FloristicSurvey)]
rownames(SpeciesComp)<-MyData[,1] # keep the quadrat names as part of your floristic survey dataframe.
library(tidyverse)
library(vegan)
library(lmtest)
library(car)
library(coefplot)
MyData$Richness<-rowSums(SpeciesComp!=0)
MyData$Shannon<-diversity(SpeciesComp, index = "shannon", MARGIN = 1, base = exp(1))
SpeciesComp.hell <- decostand(SpeciesComp, "hell")
var <-MyData[,c(2:6)] # Isolate my variables to make this whole code easier to read, since theres been no flowering we wont include it (all 0's will just mess with the analysis)
formulaRDA<- rda(SpeciesComp.hell ~ Location+Rosettes+Bolting+Budding+Population, data=var, scale=T) # notice my predictive variable are being scaled too.
head(summary(formulaRDA))
anova(formulaRDA, permutations=1000) # Is the RDA meaningful?
anova.cca(formulaRDA, by="margin", permutations=1000) # Are any predictor variables meaningful?
varpart(SpeciesComp.hell, ~Population, ~ Location, ~Rosettes + Bolting + Budding, data=var)
smry <- summary(formulaRDA)
df1  <- data.frame(smry$sites[,1:2])       # RDA1 and RDA2 (for each quadrate)
df2  <- data.frame(smry$biplot[,1:2])     # loadings for RDA1 and RDA2 (for each variable)
rda.plot <- ggplot(df1, aes(x=RDA1, y=RDA2)) +
geom_text(aes(label=rownames(df1)),size=3,position=position_jitter(width=.2,height=.2)) +
geom_point(aes(alpha=0.3)) +
geom_hline(yintercept=0, linetype="dotted") +
geom_vline(xintercept=0, linetype="dotted")
(formulaRDA.PLOT<-rda.plot +
geom_segment(data=df2, aes(x=0, xend=RDA1, y=0, yend=RDA2),
color="red", arrow=arrow(length=unit(0.01,"npc"))) +
geom_text(data=df2,
aes(x=RDA1,y=RDA2,label=rownames(df2),
hjust=0.5*(1-sign(RDA1)),vjust=0.5*(1-sign(RDA2))),
color="red", size=4)+ theme(legend.position="none"))
M <- as.matrix(SpeciesComp)
dist_M <- vegdist(M, method = "bray", binary = T)
meta.nmds <- metaMDS(dist_M, k=2, trymax = 1000) # ok so k=2 means I want 2 dimensions
#data for plotting
##NMDS points
NMDS.data<-data.frame(Location=MyData$Location,Population=MyData$Population)
NMDS.data$NMDS1<-meta.nmds$points[ ,1]
NMDS.data$NMDS2<-meta.nmds$points[ ,2]
ggplot(data = NMDS.data, aes(y = NMDS2, x = NMDS1))+
geom_point( aes(color = NMDS.data$Population,shape = NMDS.data$Location), size = 1.5,alpha=0.6)
meta.nmds <- metaMDS(dist_M, k=2, trymax = 1000) # ok so k=2 means I want 2 dimensions
#data for plotting
##NMDS points
NMDS.data<-data.frame(Location=MyData$Location,Population=MyData$Population)
NMDS.data$NMDS1<-meta.nmds$points[ ,1]
NMDS.data$NMDS2<-meta.nmds$points[ ,2]
View(NMDS.data)
